{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve bayes-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. What is Bayes' theorem?**\n",
    "\n",
    "Bayes' theorem is a principle that describes how to update the probability of a hypothesis based on new evidence. It shows the relationship between conditional probabilities and marginal probabilities. In simple terms, it allows you to revise your belief about an event based on new information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2. What is the formula for Bayes' theorem?**\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A|B) is the probability of A given B.\n",
    "P(B|A) is the probability of B given A.\n",
    "P(A) is the prior probability of A.\n",
    "P(B) is the prior probability of B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3. How is Bayes' theorem used in practice?**\n",
    "Bayes' theorem is used in various practical applications, including:\n",
    "\n",
    "Medical Diagnosis: It helps in calculating the probability of a disease given a positive test result by incorporating the test's accuracy and the disease's prevalence.\n",
    "\n",
    "Spam Filtering: In email systems, it estimates the probability that an email is spam based on the occurrence of certain words or phrases.\n",
    "\n",
    "Machine Learning: In algorithms like Naive Bayes classifier, it is used to predict the class of data points based on their features.\n",
    "\n",
    "Finance: It helps in risk assessment and decision-making by updating the probability of financial events based on new market information.\n",
    "\n",
    "Recommendation Systems: It is used to predict user preferences based on past behavior and similar users' preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4. What is the relationship between Bayes' theorem and conditional probability?**\n",
    "\n",
    "Bayes' theorem is directly related to conditional probability. It provides a way to update the probability of an event based on the occurrence of another related event.\n",
    "\n",
    "In terms of conditional probability:\n",
    "\n",
    "Conditional Probability: P(A|B) is the probability of event A occurring given that event B has already occurred.\n",
    "Bayes' theorem formulates this relationship as:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "Here:\n",
    "\n",
    "P(A|B): Conditional probability of A given B.\n",
    "P(B|A): Conditional probability of B given A.\n",
    "P(A) and P(B): Marginal probabilities of A and B, respectively.\n",
    "\n",
    "So we can say, Bayes' theorem allows you to reverse conditional probabilities by incorporating additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?**\n",
    "\n",
    "Choosing the appropriate Naive Bayes classifier depends on the nature of the data:\n",
    "\n",
    "Gaussian Naive Bayes:\n",
    "\n",
    "This classifier is chosen when the features are continuous and are assumed to follow a normal (Gaussian) distribution.\n",
    "It is often used in scenarios such as medical data analysis where features like age, height, or weight are considered to be normally distributed.\n",
    "Multinomial Naive Bayes:\n",
    "\n",
    "This type is selected for discrete data, especially when dealing with counts or frequencies.\n",
    "It is commonly applied in text classification tasks, such as email spam detection, where the features represent word counts (bag-of-words model).\n",
    "Bernoulli Naive Bayes:\n",
    "\n",
    "This classifier is suitable for binary or boolean features, indicating the presence or absence of a feature.\n",
    "It is frequently used in binary text classification tasks, such as document classification, where the presence of specific words is the feature of interest.\n",
    "The choice of the classifier should be made based on the data's characteristics—whether features are continuous, counts, or binary—and the distribution assumptions that best match the data. It is also recommended to experiment with and validate different classifiers to determine which one performs best on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6. Assignment: You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:**\n",
    "\n",
    "![alt text](sreenshot.png)\n",
    "\n",
    "**Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12, 0.12, 'B')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies_A = {'X1': {1: 3, 2: 3, 3: 4}, 'X2': {1: 4, 2: 3, 3: 3, 4: 3}}\n",
    "frequencies_B = {'X1': {1: 2, 2: 2, 3: 1}, 'X2': {1: 2, 2: 2, 3: 2, 4: 3}}\n",
    "\n",
    "total_A = sum(frequencies_A['X1'].values())\n",
    "total_B = sum(frequencies_B['X1'].values())\n",
    "\n",
    "P_X1_3_given_A = frequencies_A['X1'][3] / total_A\n",
    "P_X2_4_given_A = frequencies_A['X2'][4] / total_A\n",
    "\n",
    "P_X1_3_given_B = frequencies_B['X1'][3] / total_B\n",
    "P_X2_4_given_B = frequencies_B['X2'][4] / total_B\n",
    "\n",
    "P_A_given_X1_X2 = P_X1_3_given_A * P_X2_4_given_A\n",
    "P_B_given_X1_X2 = P_X1_3_given_B * P_X2_4_given_B\n",
    "\n",
    "if P_A_given_X1_X2 > P_B_given_X1_X2:\n",
    "    predicted_class = 'A'\n",
    "else:\n",
    "    predicted_class = 'B'\n",
    "\n",
    "P_A_given_X1_X2, P_B_given_X1_X2, predicted_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
