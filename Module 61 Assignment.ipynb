{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each.**\n",
    "\n",
    "Simple linear regression is a statistical method that models the relationship between a dependent variable and a single independent variable. It assumes a linear relationship between the two variables.   \n",
    "\n",
    "Multiple linear regression is a statistical method that models the relationship between a dependent variable and multiple independent variables. It assumes a linear relationship between the dependent variable and each independent variable.   \n",
    "- Example of simple linear regression: The relationship between the price of a house and its square footage.\n",
    "- Example of multiple linear regression: The relationship between the price of a house and its square footage, number of bedrooms, and location.\n",
    "\n",
    "**Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?**\n",
    "\n",
    "The assumptions of linear regression are:   \n",
    "\n",
    "- Linearity: The relationship between the dependent variable and the independent variables is linear.\n",
    "- Independence: The observations are independent of each other.\n",
    "- Normality: The residuals are normally distributed.\n",
    "- Homoscedasticity: The variance of the residuals is constant.   \n",
    "- No multicollinearity: The independent variables are not highly correlated with each other.\n",
    "\n",
    "You can check these assumptions by:\n",
    "- Plotting the data: Plot the data to see if it looks linear.\n",
    "- Checking the residuals: Plot the residuals against the fitted values and check for patterns.\n",
    "- Testing for normality: Use statistical tests like the Shapiro-Wilk test or the Kolmogorov-Smirnov test.\n",
    "- Testing for homoscedasticity: Use statistical tests like the Breusch-Pagan test or the Goldfeld-Quandt test.\n",
    "- Calculating the correlation matrix: Check the correlation between the independent variables.\n",
    "\n",
    "**Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario.**\n",
    "\n",
    "The slope and intercept are the parameters of the linear regression model.\n",
    "\n",
    "The slope is the change in the dependent variable for a one-unit change in the independent variable.\n",
    "\n",
    "The intercept is the value of the dependent variable when the independent variable is zero.   \n",
    "\n",
    "Example: In a linear regression model that predicts the price of a house based on its square footage, the slope represents the increase in price for each additional square foot, and the intercept represents the base price of a house with zero square footage (which is not meaningful in this context).\n",
    "\n",
    "**Q4. Explain the concept of gradient descent. How is it used in machine learning?**\n",
    "\n",
    "Gradient descent is an optimization algorithm used to find the minimum of a function. It is used in machine learning to find the optimal parameters of a model.\n",
    "\n",
    "The gradient descent algorithm works by iteratively moving in the direction of the steepest descent of the function. The step size is determined by the learning rate.\n",
    "\n",
    "**Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?**\n",
    "\n",
    "Multiple linear regression is a statistical method that models the relationship between a dependent variable and multiple independent variables. It assumes a linear relationship between the dependent variable and each independent variable.   \n",
    "\n",
    "The difference between multiple linear regression and simple linear regression is that multiple linear regression includes multiple independent variables, while simple linear regression only includes one independent variable.   \n",
    "\n",
    "**Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?**\n",
    "\n",
    "Multicollinearity is a statistical phenomenon in which two or more independent variables in a regression model are highly correlated. This can cause problems with the model, such as making it difficult to interpret the coefficients and increasing the variance of the estimates.   \n",
    "\n",
    "You can detect multicollinearity by:\n",
    "- Calculating the correlation matrix: Check the correlation between the independent variables.\n",
    "- Using variance inflation factor (VIF): Calculate the VIF for each independent variable. A VIF greater than 5 or 10 indicates high multicollinearity.\n",
    "\n",
    "You can address multicollinearity by:\n",
    "- Removing one of the correlated variables: Remove one of the independent variables that are highly correlated.\n",
    "- Combining the correlated variables: Create a new variable that combines the correlated variables.\n",
    "- Using principal component analysis (PCA): Reduce the dimensionality of the data by creating new uncorrelated variables.\n",
    "\n",
    "**Q7. Describe the polynomial regression model. How is it different from linear regression?**\n",
    "\n",
    "Polynomial regression is a statistical method that models the relationship between a dependent variable and one or more independent variables using polynomial terms.   \n",
    "\n",
    "The difference between polynomial regression and linear regression is that polynomial regression allows for non-linear relationships between the variables, while linear regression assumes a linear relationship.\n",
    "\n",
    "**Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?**\n",
    "\n",
    "Advantages of polynomial regression:\n",
    "\n",
    "- Can capture non-linear relationships between variables.\n",
    "- Can improve the accuracy of the model.\n",
    "\n",
    "Disadvantages of polynomial regression:\n",
    "- Can be overfitting if the degree of the polynomial is too high.\n",
    "- Can be difficult to interpret.\n",
    "\n",
    "Would prefer to use polynomial regression when the relationship between the variables is clearly non-linear and linear regression is not able to capture the relationship well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
