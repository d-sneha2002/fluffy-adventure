{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. What is Lasso Regression, and how does it differ from other regression techniques?**\n",
    "\n",
    "Lasso Regression is a regression analysis method that uses a shrinkage estimator to reduce the complexity of a model and prevent overfitting. It does this by adding a penalty term to the ordinary least squares regression equation, which shrinks some of the regression coefficients to zero. This has the effect of selecting the most important features and excluding the others, effectively performing feature selection.\n",
    "\n",
    "Difference from other regression techniques: Lasso Regression differs from ordinary least squares regression by adding a penalty term to the loss function. This penalty term is the L1 norm of the coefficients, which encourages sparsity in the model. Lasso Regression also differs from Ridge Regression, another regularization technique, in that the penalty term in Ridge Regression is the L2 norm of the coefficients, which does not encourage sparsity.\n",
    "\n",
    "**Q2. What is the main advantage of using Lasso Regression in feature selection?**\n",
    "\n",
    "The main advantage of Lasso Regression in feature selection is its ability to automatically select the most important features in the data. This is because the penalty term in Lasso Regression encourages some of the coefficients to be exactly zero, which effectively removes the corresponding features from the model. This can lead to simpler and more interpretable models.\n",
    " \n",
    "**Q3. How do you interpret the coefficients of a Lasso Regression model?**\n",
    "\n",
    "The coefficients of a Lasso Regression model can be interpreted in a similar way to the coefficients of an ordinary least squares regression model. However, it is important to remember that the coefficients in Lasso Regression are biased towards zero due to the shrinkage penalty. This means that the coefficients may not be as directly interpretable as in ordinary least squares regression.\n",
    "\n",
    "**Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?**\n",
    "\n",
    "The main tuning parameter in Lasso Regression is the regularization parameter, also known as lambda or alpha. This parameter controls the amount of shrinkage applied to the coefficients. A larger value of lambda will result in more shrinkage, which can lead to a simpler model but may also lead to underfitting. A smaller value of lambda will result in less shrinkage, which can lead to a more complex model but may also lead to overfitting.  \n",
    "\n",
    "**Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?**\n",
    "\n",
    "Lasso Regression is primarily a linear regression technique. However, it can be used for non-linear regression problems by transforming the features into non-linear functions, such as polynomial features or interaction terms. This process is known as basis expansion.\n",
    "\n",
    "**Q6. What is the difference between Ridge Regression and Lasso Regression?**\n",
    "\n",
    "Ridge Regression and Lasso Regression are both regularization techniques used to prevent overfitting in linear regression models. The main difference between the two is the type of penalty term used. Ridge Regression uses the L2 norm of the coefficients as the penalty term, while Lasso Regression uses the L1 norm of the coefficients. This leads to different effects on the coefficients: Ridge Regression shrinks all coefficients towards zero, while Lasso Regression can set some coefficients exactly to zero.   \n",
    "\n",
    "**Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?**\n",
    "\n",
    "Yes, Lasso Regression can handle multicollinearity in the input features. This is because the L1 penalty term in Lasso Regression encourages sparsity, which means that some coefficients will be set to zero. This can help to reduce the impact of correlated features on the model.\n",
    "\n",
    "**Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?**\n",
    "\n",
    "The optimal value of the regularization parameter (lambda) in Lasso Regression can be chosen using cross-validation. \n",
    "\n",
    "This involves splitting the data into multiple folds, training the model on a subset of the folds, and evaluating its performance on the remaining fold for different values of lambda. The value of lambda that results in the best performance on the validation set is selected as the optimal value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
